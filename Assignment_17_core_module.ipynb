{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOG9J1dVcfVq"
      },
      "outputs": [],
      "source": [
        "1. Using a graph to illustrate slope and intercept, define basic linear regression.\n",
        "2. In a graph, explain the terms rise, run, and slope.\n",
        "3. Use a graph to demonstrate slope, linear positive slope, and linear negative slope, as well as the\n",
        "different conditions that contribute to the slope."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Linear Regression:\n",
        "In linear regression, we aim to find the best-fitting line that represents the relationship between a dependent variable (y) and an independent variable (x). The line is defined by its slope (m) and intercept (b), as shown in the graph below:\n",
        "     |      .\n",
        "     |       .\n",
        "     |        .\n",
        "y    |         .\n",
        "     |           .\n",
        "     |             .\n",
        "     |____________________\n",
        "              x\n",
        "\n",
        "\n",
        "\n",
        "2. In a graph, explain the terms rise, run, and slope.\n",
        "\n",
        "Rise: The rise refers to the vertical change between two points on a line. In the graph above, it represents the change in y-axis values from (x1, y1) to (x2, y2).\n",
        "\n",
        "Run: The run refers to the horizontal change between two points on a line. In the graph above, it represents the change in x-axis values from (x1, y1) to (x2, y2).\n",
        "\n",
        "Slope: The slope represents the ratio of the rise to the run, or the change in y divided by the change in x. Mathematically, it is calculated as (y2 - y1) / (x2 - x1).\n",
        "\n",
        "\n",
        "3. Use a graph to demonstrate slope, linear positive slope, and linear negative slope, as well as the\n",
        "different conditions that contribute to the slope.\n",
        "\n",
        "Graphs Demonstrating Different Slopes:\n",
        "Here are examples of graphs demonstrating different types of slopes:\n",
        "a) Positive Slope:\n",
        "     |\n",
        "     |\n",
        "     |\n",
        "     |              .\n",
        "     |                .\n",
        "     |                  .\n",
        "     |                    .\n",
        "     |____________________\n",
        "              x\n",
        "\n",
        "b) Negative Slope\n",
        "In this graph, the line has a negative slope, indicating that y decreases as x increases. As x moves from left to right, the line goes downward.\n",
        "\n",
        "     |\n",
        "     |\n",
        "     |\n",
        "     |____________________\n",
        "              x\n",
        "     |\n",
        "     |\n",
        "     |\n",
        "     |                  .\n",
        "     |                .\n",
        "     |              .\n",
        "     |\n",
        "\n"
      ],
      "metadata": {
        "id": "pTngSCgrcxQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U8J7FXt9dIaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_me7We8WdIcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Use a graph to demonstrate curve linear negative slope and curve linear positive slope.\n",
        "\n",
        "In this graph, the curve shows a negative slope, indicating that the values decrease as x increases. The curve is concave downward, and the slope gets steeper as x increases.\n",
        "\n",
        "Curve Linear Positive Slope:\n",
        "In this graph, the curve shows a positive slope, indicating that the values increase as x increases. The curve is concave upward, and the slope gets steeper as x increases.\n",
        "\n",
        "\n",
        "5. Use a graph to show the maximum and low points of curves.\n",
        "Positive\n",
        "        .\n",
        "      .\n",
        "    .\n",
        "  .\n",
        ".\n",
        "\n",
        "Negative\n",
        "\n",
        ".\n",
        "  .\n",
        "    .\n",
        "      .\n",
        "        .\n",
        "\n",
        "\n",
        "6. Use the formulas for a and b to explain ordinary least squares.\n",
        "\n",
        "OLS is a method used in linear regression to estimate the coefficients (a and b) that define the best-fitting line. The line is chosen such that it minimizes the sum of squared differences between the observed data points and the predicted values on the line.\n",
        "The formulas for a and b in the equation of the line (y = a + bx) are derived using OLS:\n",
        "\n",
        "a (intercept) = (Σy - b * Σx) / n\n",
        "\n",
        "b (slope) = (n * Σ(xy) - Σx * Σy) / (n * Σ(x^2) - (Σx)^2)"
      ],
      "metadata": {
        "id": "xsBMP_CBdIfa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMDkdQRwdo-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Provide a step-by-step explanation of the OLS algorithm.\n",
        "\n",
        "8. What is the regression&#39;s standard error? To represent the same, make a graph.\n",
        "Regression's Standard Error:\n",
        "The standard error in regression analysis represents the average distance between the observed values of the dependent variable and the predicted values from the regression model. It quantifies the variability of the residuals or the distance between the data points and the regression line.\n",
        "\n",
        "          |    .\n",
        "          |   .\n",
        "          |  .\n",
        "          | .\n",
        "    Residual|........\n",
        "          |\n",
        "          |____________________\n",
        "                       Predicted Value\n",
        "\n",
        "\n",
        "\n",
        "9. Provide an example of multiple linear regression.\n",
        "\n",
        "Example of Multiple Linear Regression:\n",
        "Multiple linear regression involves predicting a dependent variable based on two or more independent variables. Here's an example:\n",
        "Let's say we want to predict the house price (dependent variable) based on the size of the house in square feet (x1), the number of bedrooms (x2), and the age of the house in years (x3).\n",
        "\n",
        "The multiple linear regression equation can be represented as:\n",
        "Price = b0 + b1 * Size + b2 * Bedrooms + b3 * Age\n",
        "\n",
        "10. Describe the regression analysis assumptions and the BLUE principle.\n",
        "\n",
        "Regression Analysis Assumptions and the BLUE Principle:\n",
        "Regression analysis assumes the following:\n",
        "\n",
        "Linearity: The relationship between the dependent variable and independent variables is linear.\n",
        "\n",
        "Independence: The observations are independent of each other.\n",
        "\n",
        "Homoscedasticity: The variance of the residuals is constant across all levels of the independent variables.\n",
        "\n",
        "Normality: The residuals follow a normal distribution.\n",
        "\n",
        "The BLUE (Best Linear Unbiased Estimators) principle states that in linear regression, the estimated coefficients (slopes) obtained through the least squares method are unbiased and have the minimum variance compared to any other linear unbiased estimator. This principle ensures that the OLS estimators are optimal in terms of efficiency and accuracy."
      ],
      "metadata": {
        "id": "PXSi9oAidpML"
      }
    }
  ]
}